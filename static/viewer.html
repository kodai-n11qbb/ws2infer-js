<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cam2WebRTC Viewer</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }

        .container {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        .video-container {
            margin: 20px 0;
        }

        video {
            width: 100%;
            max-width: 640px;
            height: auto;
            border-radius: 4px;
            background: #000;
        }

        .controls {
            margin: 20px 0;
        }

        input[type="text"] {
            padding: 8px;
            margin: 5px;
            border: 1px solid #ddd;
            border-radius: 4px;
            width: 200px;
        }

        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
        }

        .btn-primary {
            background-color: #007bff;
            color: white;
        }

        .btn-secondary {
            background-color: #6c757d;
            color: white;
        }

        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
        }

        .status.info {
            background-color: #d1ecf1;
            border: 1px solid #bee5eb;
            color: #0c5460;
        }

        .status.success {
            background-color: #d4edda;
            border: 1px solid #c3e6cb;
            color: #155724;
        }

        .status.error {
            background-color: #f8d7da;
            border: 1px solid #f5c6cb;
            color: #721c24;
        }

        .video-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .video-item {
            background: #f8f9fa;
            padding: 10px;
            border-radius: 4px;
        }

        .video-item h4 {
            margin: 0 0 10px 0;
            color: #495057;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>Cam2WebRTC Viewer</h1>

        <div class="controls">
            <input type="text" id="roomId" placeholder="ルームIDを入力">
            <button id="connectRoom" class="btn-primary">ルームに接続</button>
            <button id="autoConnect" class="btn-secondary">自動接続モード</button>
            <!-- Inference controls -->
            <label style="margin-left:8px;">推論間隔(ms):</label>
            <input type="number" id="inferenceIntervalMs" min="50" step="10" value="1000" style="width:100px;">
            <label style="margin-left:8px;">スケール入力:</label>
            <input type="checkbox" id="useScale" checked>
            <label style="margin-left:4px;">倍率（0.1-1.0）:</label>
            <input type="number" id="inferenceScale" min="0.1" max="1" step="0.1" value="0.5" style="width:80px;">
            <!-- Performance tuning -->
            <label style="margin-left:8px;">フレームスキップ:</label>
            <input type="number" id="frameSkip" min="0" max="10" step="1" value="0" style="width:80px;">
            <label style="margin-left:8px;">スコア閾値:</label>
            <input type="number" id="scoreThreshold" min="0" max="1" step="0.05" value="0.5" style="width:80px;">
            <label style="margin-left:8px;">最大検出数:</label>
            <input type="number" id="maxDetections" min="1" max="100" step="1" value="20" style="width:80px;">
        </div>

        <div id="status" class="status info">準備完了</div>

        <div class="video-container">
            <h3>ルーム情報:</h3>
            <div id="roomInfo">
                <p>接続数: <span id="connectionCount">0</span></p>
            </div>
        </div>

        <div class="video-grid" id="videoGrid">
            <!-- 動的にビデオ要素が追加される -->
        </div>
    </div>

    <!-- TensorFlow.js and COCO-SSD for on-device inference -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.7.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>

    <script>
        class Cam2WebRTCViewer {
            constructor() {
                this.statusDiv = document.getElementById('status');
                this.roomIdInput = document.getElementById('roomId');
                this.videoGrid = document.getElementById('videoGrid');

                this.connectionCountSpan = document.getElementById('connectionCount');

                this.ws = null;
                this.roomId = null;
                this.peerConnections = new Map();
                this.autoConnectMode = false;
                this.connectionId = this.generateConnectionId();

                this.config = null;
                this.model = null; // TF model
                this.inferenceIntervals = new Map();
                this.initializeEventListeners();
                this.loadConfig();
                this.loadModel();
                // inference settings (configurable via UI)
                this.inferenceIntervalMs = 1000; // default 1s
                this.useScale = true;
                this.inferenceScale = 0.5; // scale factor (0.1-1.0)
                this.frameSkip = 0; // skip frames: 0=every frame, 1=every other, etc
                this.scoreThreshold = 0.5; // filter out detections below this score
                this.maxDetections = 20; // limit number of detections per frame
                this.setupInferenceControls();
            }

            setupInferenceControls() {
                const intervalInput = document.getElementById('inferenceIntervalMs');
                const useScaleCb = document.getElementById('useScale');
                const scaleInput = document.getElementById('inferenceScale');

                if (intervalInput) {
                    intervalInput.value = String(this.inferenceIntervalMs);
                    intervalInput.addEventListener('change', (e) => {
                        const v = parseInt(intervalInput.value || '1000', 10);
                        this.inferenceIntervalMs = Math.max(50, isNaN(v) ? 1000 : v);
                        this.updateStatus(`推論間隔: ${this.inferenceIntervalMs}ms`, 'info');
                        this.restartAllInference();
                    });
                }

                if (useScaleCb) {
                    useScaleCb.checked = this.useScale;
                    useScaleCb.addEventListener('change', () => {
                        this.useScale = useScaleCb.checked;
                        this.updateStatus(`スケール入力: ${this.useScale ? '有効' : '無効'}`, 'info');
                        this.restartAllInference();
                    });
                }

                if (scaleInput) {
                    scaleInput.value = String(this.inferenceScale);
                    scaleInput.addEventListener('change', () => {
                        let v = parseFloat(scaleInput.value || '0.5');
                        if (isNaN(v) || v <= 0) v = 0.5;
                        this.inferenceScale = Math.min(1.0, Math.max(0.1, v));
                        scaleInput.value = String(this.inferenceScale);
                        this.updateStatus(`入力スケール: ${this.inferenceScale}`, 'info');
                        this.restartAllInference();
                    });
                }

                const frameSkipInput = document.getElementById('frameSkip');
                if (frameSkipInput) {
                    frameSkipInput.value = String(this.frameSkip);
                    frameSkipInput.addEventListener('change', () => {
                        const v = parseInt(frameSkipInput.value || '0', 10);
                        this.frameSkip = Math.max(0, isNaN(v) ? 0 : v);
                        this.updateStatus(`フレームスキップ: ${this.frameSkip}`, 'info');
                        this.restartAllInference();
                    });
                }

                const scoreThresholdInput = document.getElementById('scoreThreshold');
                if (scoreThresholdInput) {
                    scoreThresholdInput.value = String(this.scoreThreshold);
                    scoreThresholdInput.addEventListener('change', () => {
                        let v = parseFloat(scoreThresholdInput.value || '0.5');
                        if (isNaN(v)) v = 0.5;
                        this.scoreThreshold = Math.min(1.0, Math.max(0, v));
                        scoreThresholdInput.value = String(this.scoreThreshold);
                        this.updateStatus(`スコア閾値: ${this.scoreThreshold.toFixed(2)}`, 'info');
                        // No restart needed, applies next frame
                    });
                }

                const maxDetectionsInput = document.getElementById('maxDetections');
                if (maxDetectionsInput) {
                    maxDetectionsInput.value = String(this.maxDetections);
                    maxDetectionsInput.addEventListener('change', () => {
                        const v = parseInt(maxDetectionsInput.value || '20', 10);
                        this.maxDetections = Math.max(1, isNaN(v) ? 20 : v);
                        this.updateStatus(`最大検出数: ${this.maxDetections}`, 'info');
                        // No restart needed, applies next frame
                    });
                }
            }

            restartAllInference() {
                // Restart inference loops for all active senders to apply new settings
                for (const senderId of Array.from(this.inferenceIntervals.keys())) {
                    try {
                        this.stopInferenceForVideo(senderId);
                        const container = document.getElementById(`video-${senderId}`);
                        if (container) {
                            const videoElem = container.querySelector('video');
                            if (videoElem) {
                                this.startInferenceForVideo(senderId, videoElem);
                            }
                        }
                    } catch (e) {
                        console.error('Error restarting inference for', senderId, e);
                    }
                }
            }

            async loadModel() {
                try {
                    this.updateStatus('TFモデル読み込み中...', 'info');
                    // Load coco-ssd model
                    this.model = await cocoSsd.load();
                    this.updateStatus('TFモデル読み込み完了', 'success');
                } catch (e) {
                    console.error('モデル読み込み失敗', e);
                    this.updateStatus('TFモデルの読み込みに失敗しました', 'error');
                }
            }

            async loadConfig() {
                try {
                    const response = await fetch('/api/config');
                    if (response.ok) {
                        this.config = await response.json();
                        console.log('Config loaded:', this.config);
                    }
                } catch (e) {
                    console.error('Failed to load config:', e);
                }
            }

            initializeEventListeners() {
                document.getElementById('connectRoom').addEventListener('click', () => this.connectToRoom());
                document.getElementById('autoConnect').addEventListener('click', () => this.toggleAutoConnect());

                // URLパラメータからルームIDを取得
                const urlParams = new URLSearchParams(window.location.search);
                const roomId = urlParams.get('room');
                if (roomId) {
                    this.roomIdInput.value = roomId;
                    this.connectToRoom();
                }
            }

            async connectToRoom() {
                const roomId = this.roomIdInput.value.trim();
                if (!roomId) {
                    this.updateStatus('ルームIDを入力してください', 'error');
                    return;
                }

                this.roomId = roomId;
                await this.startConnection();
            }

            toggleAutoConnect() {
                this.autoConnectMode = !this.autoConnectMode;
                const btn = document.getElementById('autoConnect');

                if (this.autoConnectMode) {
                    btn.textContent = '自動接続停止';
                    btn.className = 'btn-primary';
                    this.startAutoConnect();
                    this.updateStatus('自動接続モードを開始', 'info');
                } else {
                    btn.textContent = '自動接続モード';
                    btn.className = 'btn-secondary';
                    this.stopAutoConnect();
                    this.updateStatus('自動接続モードを停止', 'info');
                }
            }

            startAutoConnect() {
                // 定期的にルームを監視
                this.autoConnectInterval = setInterval(() => {
                    this.checkForRooms();
                }, 5000);
            }

            stopAutoConnect() {
                if (this.autoConnectInterval) {
                    clearInterval(this.autoConnectInterval);
                    this.autoConnectInterval = null;
                }
            }

            async checkForRooms() {
                // 簡易的な実装 - 実際はAPIから利用可能なルームを取得
                // ここではデモ用に固定ルームIDを試す
                const commonRoomIds = ['demo', 'test', 'public'];

                for (const roomId of commonRoomIds) {
                    try {
                        const response = await fetch(`/api/rooms/${roomId}`);
                        if (response.ok) {
                            this.roomIdInput.value = roomId;
                            this.updateStatus(`ルーム ${roomId} を検出しました`, 'success');
                            await this.connectToRoom();
                            break;
                        }
                    } catch (error) {
                        // ルームが存在しない場合は無視
                    }
                }
            }

            async startConnection() {
                try {
                    this.updateStatus(`ルーム ${this.roomId} に接続中...`, 'info');

                    // Connect to WebSocket (use relative path)
                    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                    this.ws = new WebSocket(`${protocol}//${window.location.host}/ws/${this.roomId}`);

                    this.ws.onopen = () => {
                        this.updateStatus('WebSocket接続完了', 'success');
                        this.joinRoom();
                    };

                    this.ws.onmessage = (event) => {
                        this.handleSignalingMessage(JSON.parse(event.data));
                    };

                    this.ws.onerror = (error) => {
                        this.updateStatus(`WebSocketエラー: 接続きません`, 'error');
                        console.error(error);
                    };

                    this.ws.onclose = () => {
                        this.updateStatus('WebSocket接続が切断されました', 'error');
                        if (this.autoConnectMode) {
                            // 自動再接続
                            setTimeout(() => this.startConnection(), 3000);
                        }
                    };
                } catch (error) {
                    this.updateStatus(`接続エラー: ${error.message}`, 'error');
                }
            }

            joinRoom() {
                const message = {
                    type: 'join',
                    connection_id: this.connectionId,
                    is_sender: false
                };
                if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                    this.ws.send(JSON.stringify(message));
                }
            }

            async handleSignalingMessage(message) {
                switch (message.type) {
                    case 'room_info':
                        this.updateStatus(`ルームに接続しました (P2P Mesh)`, 'info');
                        if (message.data.connection_count !== undefined) {
                            this.connectionCountSpan.textContent = message.data.connection_count;
                        }
                        break;

                    case 'new_peer':
                        this.updateStatus(`新しいピアが参加しました: ${message.data.connection_id}`, 'info');
                        if (message.data.connection_count !== undefined) {
                            this.connectionCountSpan.textContent = message.data.connection_count;
                        }
                        break;

                    case 'leave':
                        this.updateStatus(`ピアが退出しました: ${message.data.connection_id}`, 'info');
                        if (message.data.connection_count !== undefined) {
                            this.connectionCountSpan.textContent = message.data.connection_count;
                        }
                        // Cleanup peer connection if it exists
                        if (this.peerConnections.has(message.data.connection_id)) {
                            const pc = this.peerConnections.get(message.data.connection_id);
                            pc.close();
                            this.peerConnections.delete(message.data.connection_id);
                            // Stop inference and remove UI
                            this.stopInferenceForVideo(message.data.connection_id);
                            const videoElem = document.getElementById(`video-${message.data.connection_id}`);
                            if (videoElem) videoElem.remove();
                        }
                        break;

                    case 'offer':
                        await this.handleOffer(message);
                        break;

                    case 'ice_candidate':
                        await this.handleIceCandidate(message);
                        break;

                    case 'error':
                        this.updateStatus(`エラー: ${message.data.error}`, 'error');
                        break;
                }
            }

            async handleOffer(message) {
                const senderId = message.sender_id;
                this.updateStatus(`オファーを受信 (Sender: ${senderId})`, 'info');

                // Close existing connection from this sender if any
                if (this.peerConnections.has(senderId)) {
                    this.peerConnections.get(senderId).close();
                }

                const config = {
                    iceServers: this.config?.ice_servers || [
                        { urls: 'stun:localhost:3478' }
                    ]
                };

                const pc = new RTCPeerConnection(config);
                this.peerConnections.set(senderId, pc);

                // Create video element for this sender
                let videoContainer = document.getElementById(`video-${senderId}`);
                if (!videoContainer) {
                    videoContainer = document.createElement('div');
                    videoContainer.id = `video-${senderId}`;
                    videoContainer.className = 'video-item';

                    const title = document.createElement('h4');
                    title.textContent = `Sender: ${senderId}`;

                    const video = document.createElement('video');
                    video.autoplay = true;
                    video.playsInline = true;
                    video.controls = true; // Add controls for debugging

                    videoContainer.appendChild(title);
                    videoContainer.appendChild(video);
                    this.videoGrid.appendChild(videoContainer);
                }

                const videoElement = videoContainer.querySelector('video');

                // Handle Track
                pc.ontrack = (event) => {
                    console.log('Track received:', event.streams);
                    if (event.streams && event.streams[0]) {
                        videoElement.srcObject = event.streams[0];
                        this.updateStatus('映像を受信中...', 'success');
                        // Start inference for this incoming video
                        // Wait until video is playing
                        videoElement.addEventListener('playing', () => {
                            this.startInferenceForVideo(senderId, videoElement);
                        }, { once: true });
                    }
                };

                // Handle ICE candidates
                pc.onicecandidate = (event) => {
                    if (event.candidate) {
                        const candidateMessage = {
                            type: 'ice_candidate',
                            connection_id: senderId, // Target the sender
                            sender_id: this.connectionId,
                            data: event.candidate
                        };
                        this.ws.send(JSON.stringify(candidateMessage));
                    }
                };

                try {
                    await pc.setRemoteDescription(new RTCSessionDescription(message.data));
                    const answer = await pc.createAnswer();
                    await pc.setLocalDescription(answer);

                    const answerMessage = {
                        type: 'answer',
                        connection_id: senderId, // Target the sender
                        sender_id: this.connectionId,
                        data: answer
                    };
                    this.ws.send(JSON.stringify(answerMessage));
                    this.updateStatus('アンサー送信完了', 'success');

                } catch (error) {
                    console.error('Error handling offer:', error);
                    this.updateStatus(`オファー処理エラー: ${error.message}`, 'error');
                }
            }

            startInferenceForVideo(senderId, videoElement) {
                if (!this.model) return;
                // If already running for this sender, skip
                if (this.inferenceIntervals.has(senderId)) return;

                // Create or find overlay element
                let container = document.getElementById(`video-${senderId}`);
                // Ensure container is positioned for absolute overlay
                container.style.position = 'relative';

                // Text overlay (simple top-left status)
                let overlay = container.querySelector('.detection-overlay');
                if (!overlay) {
                    overlay = document.createElement('div');
                    overlay.className = 'detection-overlay';
                    overlay.style.position = 'absolute';
                    overlay.style.left = '6px';
                    overlay.style.top = '6px';
                    overlay.style.padding = '6px';
                    overlay.style.fontSize = '12px';
                    overlay.style.background = 'rgba(255,255,255,0.7)';
                    overlay.style.borderRadius = '4px';
                    overlay.style.color = '#222';
                    overlay.style.zIndex = '5';
                    container.appendChild(overlay);
                }

                // Canvas overlay for drawing boxes
                let canvas = container.querySelector('.detection-canvas');
                if (!canvas) {
                    canvas = document.createElement('canvas');
                    canvas.className = 'detection-canvas';
                    canvas.style.position = 'absolute';
                    canvas.style.left = '0';
                    canvas.style.top = '0';
                    canvas.style.width = '100%';
                    canvas.style.height = '100%';
                    canvas.style.pointerEvents = 'none';
                    canvas.style.zIndex = '4';
                    container.appendChild(canvas);
                }
                const ctx = canvas.getContext('2d');

                // Helper to resize canvas to video pixels
                const resizeCanvas = () => {
                    const vw = videoElement.videoWidth || videoElement.clientWidth;
                    const vh = videoElement.videoHeight || videoElement.clientHeight;
                    // Set canvas internal size to video pixel size for crisp boxes
                    if (vw && vh) {
                        canvas.width = vw;
                        canvas.height = vh;
                    } else {
                        // fallback to client size
                        canvas.width = videoElement.clientWidth;
                        canvas.height = videoElement.clientHeight;
                    }
                };

                // Prepare optional offscreen (scaled) canvas for faster inference
                let offscreen = null;
                const getScale = () => (this.useScale ? this.inferenceScale : 1.0);
                const ensureOffscreen = () => {
                    const scale = getScale();
                    if (scale >= 1) {
                        offscreen = null;
                        return;
                    }
                    if (!offscreen) offscreen = document.createElement('canvas');
                    const vw = videoElement.videoWidth || videoElement.clientWidth;
                    const vh = videoElement.videoHeight || videoElement.clientHeight;
                    offscreen.width = Math.max(1, Math.round((vw) * scale));
                    offscreen.height = Math.max(1, Math.round((vh) * scale));
                };

                // Frame counter for frame skip logic
                let frameCount = 0;

                // Run detection periodically using configured interval
                const interval = setInterval(async () => {
                    try {
                        if (videoElement.readyState < 2) return;

                        // Apply frame skip: only run inference on appropriate frames
                        if (this.frameSkip > 0 && frameCount % (this.frameSkip + 1) !== 0) {
                            frameCount++;
                            return;
                        }
                        frameCount++;

                        // Ensure canvas matches video size
                        resizeCanvas();

                        const scale = getScale();
                        let predictions = [];

                        if (scale < 1) {
                            // Create/update offscreen scaled canvas
                            ensureOffscreen();
                            const offctx = offscreen.getContext('2d');
                            offctx.drawImage(videoElement, 0, 0, offscreen.width, offscreen.height);
                            predictions = await this.model.detect(offscreen);
                        } else {
                            predictions = await this.model.detect(videoElement);
                        }

                        // Apply score threshold filter and limit to maxDetections
                        predictions = predictions
                            .filter(p => p.score >= this.scoreThreshold)
                            .slice(0, this.maxDetections);

                        // Update text overlay with top results
                        overlay.innerHTML = predictions.slice(0, 3).map(p => `${p.class} (${(p.score*100).toFixed(0)}%)`).join('<br>') || '検出なし';

                        // Clear canvas then draw boxes (scale bbox back to original video pixels if needed)
                        ctx.clearRect(0, 0, canvas.width, canvas.height);
                        ctx.lineWidth = Math.max(2, Math.round(canvas.width / 200));
                        ctx.font = `${Math.max(12, Math.round(canvas.width / 50))}px Arial`;
                        const scaleBack = scale < 1 ? (1.0 / scale) : 1.0;
                        const sanitizedForServer = predictions.map(p => {
                            const b = p.bbox;
                            return {
                                class: p.class,
                                score: p.score,
                                bbox: [b[0] * scaleBack, b[1] * scaleBack, b[2] * scaleBack, b[3] * scaleBack]
                            };
                        });

                        predictions.forEach((p, idx) => {
                            const bbox = p.bbox; // coordinates in input pixels (maybe scaled)
                            const x = bbox[0] * scaleBack;
                            const y = bbox[1] * scaleBack;
                            const w = bbox[2] * scaleBack;
                            const h = bbox[3] * scaleBack;

                            // Draw box
                            ctx.strokeStyle = 'rgba(0,200,0,0.9)';
                            ctx.fillStyle = 'rgba(0,200,0,0.2)';
                            ctx.beginPath();
                            ctx.rect(x, y, w, h);
                            ctx.stroke();

                            // Draw label background
                            const label = `${p.class} ${(p.score*100).toFixed(0)}%`;
                            const textWidth = ctx.measureText(label).width;
                            const textHeight = parseInt(ctx.font, 10) + 4;
                            ctx.fillStyle = 'rgba(0,200,0,0.7)';
                            ctx.fillRect(x, Math.max(0, y - textHeight), textWidth + 6, textHeight);

                            // Draw label text
                            ctx.fillStyle = '#fff';
                            ctx.fillText(label, x + 3, Math.max(0, y - 4));
                        });

                        // Send results to server (sanitized, in original video pixels)
                        this.sendInferenceResults(senderId, sanitizedForServer);
                    } catch (e) {
                        console.error('Inference error', e);
                    }
                }, this.inferenceIntervalMs);

                // Ensure canvas resized when metadata available or on window resize
                videoElement.addEventListener('loadedmetadata', resizeCanvas, { once: true });
                window.addEventListener('resize', resizeCanvas);

                this.inferenceIntervals.set(senderId, { intervalId: interval, canvasListener: resizeCanvas });
            }

            stopInferenceForVideo(senderId) {
                if (this.inferenceIntervals.has(senderId)) {
                    const info = this.inferenceIntervals.get(senderId);
                    // stored object: { intervalId, canvasListener }
                    if (info && info.intervalId) clearInterval(info.intervalId);
                    if (info && info.canvasListener) window.removeEventListener('resize', info.canvasListener);
                    this.inferenceIntervals.delete(senderId);
                }
                const container = document.getElementById(`video-${senderId}`);
                if (container) {
                    const overlay = container.querySelector('.detection-overlay');
                    if (overlay) overlay.remove();
                    const canvas = container.querySelector('.detection-canvas');
                    if (canvas) canvas.remove();
                }
                // remove window resize listener might be skipped for simplicity
            }

            sendInferenceResults(sourceSenderId, predictions) {
                if (!this.ws || this.ws.readyState !== WebSocket.OPEN) return;
                const sanitized = predictions.map(p => ({ class: p.class, score: p.score, bbox: p.bbox }));
                const message = {
                    type: 'inference_result',
                    room_id: this.roomId,
                    sender_id: this.connectionId, // viewer id reporting
                    source_sender_id: sourceSenderId, // original camera sender
                    data: {
                        timestamp: Date.now(),
                        predictions: sanitized
                    }
                };
                try {
                    this.ws.send(JSON.stringify(message));
                } catch (e) {
                    console.error('Failed to send inference result', e);
                }
            }

            async handleIceCandidate(message) {
                // Find the appropriate peer connection using sender_id
                // sender_id in the message corresponds to the ID we used to store the PC
                const senderId = message.sender_id;

                if (senderId && this.peerConnections.has(senderId)) {
                    const pc = this.peerConnections.get(senderId);
                    if (pc.signalingState !== 'closed') {
                        try {
                            await pc.addIceCandidate(new RTCIceCandidate(message.data));
                        } catch (error) {
                            console.error("Error adding ICE candidate", error);
                        }
                    }
                }
            }

            generateConnectionId() {
                return 'viewer_' + Math.random().toString(36).substr(2, 9);
            }

            updateStatus(message, type) {
                this.statusDiv.textContent = message;
                this.statusDiv.className = `status ${type}`;
                console.log(`[${type.toUpperCase()}] ${message}`);
            }
        }

        // Initialize application
        document.addEventListener('DOMContentLoaded', () => {
            new Cam2WebRTCViewer();
        });
    </script>
</body>

</html>