flowchart TD
  subgraph "Sender (配信者)"
    S[getUserMedia<br/>カメラ/マイク取得]
    PC_MGR["Connection Manager<br/>(Viewer毎にPC生成: Mesh方式)"]
  end
  
  subgraph "Rust Signaling Server"
    WS[WebSocket Server]
    ROOM[Room管理<br/>RoomManagerが推論集約とDBを内包]
    
    STUN["内蔵STUN Server<br/>UDP:3478"]
    TURN["内蔵TURN Server<br/>UDP:3479"]
  end
  
  subgraph "Viewers (視聴者)"
    V1[Viewer 1<br/>TF.js推論 & 設定UI]
    V2[Viewer 2<br/>TF.js推論 & 設定UI]
    VN[Viewer N<br/>TF.js推論 & 設定UI]
  end

  %% ストリームの流れ
  S --> PC_MGR

  %% Signaling Flow
  PC_MGR <-->|"WebSocket: Signaling"| WS
  WS <-->|WebSocket: Signaling| V1
  WS <-->|WebSocket: Signaling| V2
  WS <-->|WebSocket: Signaling| VN
  
  %% Server Logic
  WS --- ROOM
  
  %% ICE/STUN/TURN Flow
  PC_MGR -.->|UDP: ICE Check| STUN
  V1 -.->|UDP: ICE Check| STUN
  V2 -.->|UDP: ICE Check| STUN
  
  PC_MGR -.->|"UDP: Relay"| TURN
  V1 -.->|"UDP: Relay"| TURN
  V2 -.->|"UDP: Relay"| TURN
  
  %% P2P Data Flow (Mesh)
  PC_MGR <==>|WebRTC: P2P Stream| V1
  PC_MGR <==>|WebRTC: P2P Stream| V2
  PC_MGR <==>|WebRTC: P2P Stream| VN

  %% Viewer推論 → サーバー報告フロー
  V1 --> V1_TF["TensorFlow.js<br/>モデル推論"]
  V1_TF <-->|"WebSocket:<br/>inference_result"| WS
  
  V2 --> V2_TF["TensorFlow.js<br/>モデル推論"]
  V2_TF <-->|"WebSocket:<br/>inference_result"| WS
  
  VN --> VN_TF["TensorFlow.js<br/>モデル推論"]
  VN_TF <-->|"WebSocket:<br/>inference_result"| WS

  %% サーバー内推論管理フロー
  WS --> ROOM
  ROOM <-->|"推論結果の保存/集約/配信 (in-memory)"| ROOM
